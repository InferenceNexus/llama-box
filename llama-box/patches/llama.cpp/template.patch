diff --git a/src/llama.cpp b/src/llama.cpp
index 8b799e0e..f3d623ed 100644
--- a/src/llama.cpp
+++ b/src/llama.cpp
@@ -1630,6 +1630,9 @@ enum llm_chat_template {
     LLM_CHAT_TEMPLATE_RWKV_WORLD,
     LLM_CHAT_TEMPLATE_GRANITE,
     LLM_CHAT_TEMPLATE_GIGACHAT,
+    LLM_CHAT_TEMPLATE_FALCON,
+    LLM_CHAT_TEMPLATE_LLAVA,
+    LLM_CHAT_TEMPLATE_LLAVA_MISTRAL,
     LLM_CHAT_TEMPLATE_UNKNOWN,
 };
 
@@ -1662,6 +1665,9 @@ static const std::map<std::string, llm_chat_template> LLM_CHAT_TEMPLATES = {
     { "rwkv-world",        LLM_CHAT_TEMPLATE_RWKV_WORLD        },
     { "granite",           LLM_CHAT_TEMPLATE_GRANITE           },
     { "gigachat",          LLM_CHAT_TEMPLATE_GIGACHAT          },
+    { "falcon",            LLM_CHAT_TEMPLATE_FALCON            },
+    { "llava",             LLM_CHAT_TEMPLATE_LLAVA             },
+    { "llava-mistral",     LLM_CHAT_TEMPLATE_LLAVA_MISTRAL     },
 };
 
 static llm_arch llm_arch_from_string(const std::string & name) {
@@ -22265,6 +22271,8 @@ static llm_chat_template llama_chat_detect_template(const std::string & tmpl) {
         return LLM_CHAT_TEMPLATE_GRANITE;
     } else if (tmpl_contains("message['role'] + additional_special_tokens[0] + message['content'] + additional_special_tokens[1]")) {
         return LLM_CHAT_TEMPLATE_GIGACHAT;
+    }  else if ((tmpl_contains("Falcon:") && tmpl_contains("message['content']"))) {
+        return LLM_CHAT_TEMPLATE_FALCON;
     }
     return LLM_CHAT_TEMPLATE_UNKNOWN;
 }
@@ -22614,6 +22622,61 @@ static int32_t llama_chat_apply_template_internal(
         if (add_ass) {
             ss << "assistant<|role_sep|>";
         }
+    } else if (tmpl == LLM_CHAT_TEMPLATE_FALCON) {
+        // Falcon
+        std::string system_prompt;
+        for (const auto &message : chat) {
+            std::string role(message->role);
+            if (role == "system") {
+                system_prompt = trim(message->content);
+            } else if (role == "user") {
+                if (!system_prompt.empty()) {
+                    ss << "\n" << system_prompt << "\n\n\n";
+                    system_prompt = "";
+                }
+                ss << "\nUser: " << trim(message->content) << "\n\n\n";
+            } else if (role == "assistant") {
+                ss << "\nAssistant: " << trim(message->content) << "\n\n\n";
+            }
+        }
+        if (add_ass) {
+            ss << "\nAssistant:";
+        }
+    } else if (tmpl == LLM_CHAT_TEMPLATE_LLAVA || tmpl == LLM_CHAT_TEMPLATE_LLAVA_MISTRAL) {
+        // llava 1.5
+        if (tmpl != LLM_CHAT_TEMPLATE_LLAVA_MISTRAL) {
+            ss << "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n";
+        }
+        for (auto message : chat) {
+            std::string role(message->role);
+            if (role == "user") {
+                std::string content(message->content);
+                if (tmpl != LLM_CHAT_TEMPLATE_LLAVA_MISTRAL) {
+                    ss << "USER:" << message->content << "\n";
+                } else {
+                    const std::string sign = "<image>\n";
+                    const size_t sign_pos = content.find(sign);
+                    if (sign_pos != std::string::npos) {
+                        content = content.replace(sign_pos, sign.size(), "");
+                        ss << "<image>\n";
+                    }
+                    ss << "USER:\n" << content.c_str() << "\n";
+                }
+            } else if (role == "assistant") {
+                if (tmpl != LLM_CHAT_TEMPLATE_LLAVA_MISTRAL) {
+                    ss << "ASSISTANT:" << message->content << "</s>\n";
+                } else {
+                    ss << "ASSISTANT:\n" << message->content << "</s>\n";
+                }
+            }
+        }
+        if (add_ass) {
+            if (tmpl != LLM_CHAT_TEMPLATE_LLAVA_MISTRAL) {
+                ss << "ASSISTANT:";
+            } else {
+                ss << "ASSISTANT:\n";
+            }
+        }
     } else {
         // template not supported
         return -1;
